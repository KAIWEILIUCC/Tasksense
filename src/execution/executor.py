import copy
import os
import time

import yaml

from src.execution.dynamic_plan_adaptation.adjuster import adjust_plan
from src.execution.toolbox import tool_name_tool_implementation_map
from TaskSense.src.responding.formatter import (aggregate_results,
                                                 find_interupt,
                                                 format_results_to_dict)
from src.utils import generate_a_sign, pack_result, print_tips


# define the worker function
# this function is used to execute a tool call in a separate process
# the tool call is executed in the worker function
def worker(
    results_collection,
    tool_call,
    execution_time_of_each_tool_call,
    gflops_of_each_tool_call
):
    '''
    This function executes a tool call.

    Args:
        user_input (str): the user input string
        results_collection (dict): the dictionary for storing the results of tool calls
        tool_call (dict): the dictionary representing the tool call
        execution_time_of_each_tool_call (dict): the dictionary for storing the execution time of each tool call
        
    Returns:
        bool: whether the tool call is executed successfully
    '''
    
    # print the ps id and the memory usage
    
    # initilze the input dict to tool
    input_to_tool = {
        "tool_name": tool_call["tool_name"],
        "output": {
            "pre_sign": [],
            "post_sign": []
        },
        "saving": True,
        "execute_next": True
    }
    
    # tool call id
    tool_call_id = tool_call["id"]
    # tool name
    tool_name = tool_call["tool_name"]
    # dependency
    dep = tool_call["dep"]
    # arguments
    args = tool_call["args"]
    
    # fetch the reuslts generated by the previous tool calls
    if dep[0] != -1:
        dep_results = [results_collection[dep_id] for dep_id in dep]
    else:
        dep_results = []
    
    # initialize the execute_next flag to True    
    execute_next = True
    
    # check the execute next flag of the previous tool calls, if any of them is False, then set the execute_next flag to False
    for dep_result in dep_results:
        if not dep_result["tool_calling_result"]["execute_next"]:
            execute_next = False
            break
        
    # if the execute_next flag is True, 
    # then fetch the results of the dependent tool calls 
    # and add them to the input to the tool
    
    if execute_next:
        try:
            # read the configuration file to get the used modalities list
            config_path = os.environ["CONFIG_PATH"]
            config = yaml.load(open(config_path), Loader=yaml.FullLoader)
            dataset_name = config["dataset_name"]
            used_modalities = config["execution_settings"]["modalities"][dataset_name]
            
            for modality in used_modalities:
                modality_result = None
                
                # if the modality is in the output of the previous tool calls,
                # then get the result of the modality
                # and add them to the input to the tool
                for dep_result in dep_results:
                    if modality in dep_result["tool_calling_result"]["output"]:
                        modality_result = dep_result["tool_calling_result"]["output"][modality]
                        input_to_tool["output"][modality] = dep_result["tool_calling_result"]["output"][modality]
                        input_to_tool["output"]["post_sign"] += dep_result["tool_calling_result"]["output"]["post_sign"]
                
                if modality in args:
                        
                    # if the modality is in the arguments of the tool call,
                    # then get the result of the modality
                    if "<GENERATED>" in args[modality] and modality_result is not None:
                            args[modality] = modality_result

                    # if this tool call is not dependent on the previous tool calls,
                    # then the input_to_tool["output"]["post_sign"] should be empty
                    # and we need to generate a new post_sign list for this tool call
                    if len(input_to_tool["output"]["post_sign"]) == 0:
                        input_to_tool["output"][modality] = args[modality]
                        new_post_sign_list = []
                        for _ in range(len(input_to_tool["output"][modality])):
                            new_post_sign_list.append(generate_a_sign())
                        input_to_tool["output"]["post_sign"] = new_post_sign_list
        except Exception as e:
            print(f"Error occurred while preparing the input to the tool: {e}")
    
    if dep[0] != -1:
        input_to_tool["execute_next"] = execute_next
        
    tool_call["args"] = args
    
    # if the tool name is not in the tool_name_tool_implementation_map,
    # then raise an error
    
    if tool_name not in tool_name_tool_implementation_map:
        raise ValueError(f"Tool name {tool_name} is not in the tool_name_tool_implementation_map.")
    
    # if the tool name is in the tool_name_tool_implementation_map,
    # then execute the tool
    else:
        # initialize the dict to store the execution time of the tool call
        time_of_each_stage_of_tool_execution = {
            "tool_name": tool_name,
            "total_time": None,
            "pre_processing_time": None,
            "model_loading_time": None,
            "model_inference_time": None,
        }
        
        gflops_of_tool = {
            "tool_name": tool_name,
            "gflops": None,
        }
        
        # get the tool implementation
        tool_selected = tool_name_tool_implementation_map[tool_name]
        
        # execute the tool
        # and record the time of the tool execution
        tool_start_time = time.perf_counter()
        
        try:
            execution_result = tool_selected(
                args=input_to_tool,
                time_of_each_stage_of_tool_execution=time_of_each_stage_of_tool_execution,
                gflops_of_tool=gflops_of_tool
            )
        except Exception as e:
            print(f"Error occurred while executing tool {tool_name}: {e}")
        
        tool_end_time = time.perf_counter()
        time_of_each_stage_of_tool_execution["total_time"] = tool_end_time - tool_start_time
        
        # if there is 'error' in the execution result,
        # then raise an error
        if "error" in execution_result:
            raise ValueError(f"Error occurred while executing tool {tool_name}: {execution_result['error']}")
        
        # if the current tool call is the first tool call,
        # the dep needs to be adjusted
        #
        if dep[0] == -1:
            results_collection[-1 * (tool_call_id + 1)] = pack_result({
                "tool_name": "initial input",
                "id": -1 * (tool_call_id + 1),
                "dep": []
            }, input_to_tool)
        
        # add the tool call information and the execution result to the results collection
        results_collection[tool_call_id] = pack_result(
            tool_call,
            execution_result
        )
        
        # add the time of the tool execution to the execution_time_of_each_tool_call
        execution_time_of_each_tool_call[tool_call_id] = time_of_each_stage_of_tool_execution.copy()
        
        # add the GFLOPs of the tool to the gflops_of_each_tool_call
        gflops_of_each_tool_call[tool_call_id] = gflops_of_tool.copy()
        
        return True 

# define the execute_plan function
# this function is used to execute the plan
def execute_plan(
    user_input,
    data_structure_pool,
    plan,
):
    '''
    This function executes the plan.

    Args:
        user_input (str): the user input string
        data_structure_pool (DataStructurePool): the data structure pool
        plan (list): the plan list, comtaining several dictionaries, each of which represents a tool call
        
    Returns:
        dict: the packed result
    '''
    
    # clear the data structure
    data_structure_pool.clear()
    # acquire the data structure
    tool_calls, d, pool, execution_time_of_each_tool_call, gflops_of_each_tool_call = data_structure_pool.acquire()
    # copy the plan into the tool calls list
    tool_calls[:] = plan
    # times of retries
    retries = 0
    
    tool_call_results_list = []
    
    while True:
        # record the initial number of tool calls
        initial_tool_calls_num = len(tool_calls)
        
        # submit each tool call to the pool
        for tool_call in tool_calls:
            # if the tool call has no dependency
            for dep_id in tool_call["dep"]:
                if dep_id >= tool_call["id"]:
                    tool_call["dep"] = [-1]
                    break
            dep = tool_call["dep"]
            if dep[0] == -1 or len(list(set(dep).intersection(d.keys()))) == len(dep):
                try:
                    # get the tool call result
                    tool_call_result = pool.apply_async(worker, (d, tool_call, execution_time_of_each_tool_call, gflops_of_each_tool_call))
                    # append the tool call result to the tool call results list
                    tool_call_results_list.append(tool_call_result)
                except Exception as e:
                    print_tips(
                        f"Error occurred while submitting tool call {tool_call['id']} to the pool: {e}",
                        emoji="warning",
                        text_color="red",
                        border=False
                    )
                    
                tool_calls.remove(tool_call)
        
        # if there is no new tool call submitted, then wait for 0.5 second and retry
        if len(tool_calls) == initial_tool_calls_num:
            time.sleep(0.5)
            retries += 1
        
        # if all tool calls are executed, then break
        if len(tool_calls) == 0:
            break
    
    # wait for all tool calls to finish
    for tool_call_result in tool_call_results_list:
        tool_call_result.wait()
    
    results = dict(d)
    config_path = os.environ["CONFIG_PATH"]
    config = yaml.load(open(config_path), Loader=yaml.FullLoader)
    measure_flops = config["execution_settings"]["measure_flops"]
    
    return results

def execute(
    user_input,
    data_structure_pool,
    plan,
):
    config_path = os.environ["CONFIG_PATH"]
    config = yaml.load(open(config_path), Loader=yaml.FullLoader)
    use_dynamic_plan_adaptation = config["execution_settings"]["use_dynamic_plan_adaptation"]
    
    if use_dynamic_plan_adaptation:
        config_path = os.environ["CONFIG_PATH"]
        config = yaml.load(open(config_path), Loader=yaml.FullLoader)
        cumulative_avg_flops_path = config["execution_settings"]["cumulative_avg_flops_path"]
        
        os.makedirs(os.path.dirname(cumulative_avg_flops_path), exist_ok=True)
        
        map_from_time_interval_to_filtered_alternative_list, unexecutable_time_ranges = adjust_plan(
            plan
        )
        
        results_of_each_time_range = {}
        
        for time_range_str in map_from_time_interval_to_filtered_alternative_list:
            if time_range_str not in results_of_each_time_range:
                results_of_each_time_range[time_range_str] = []
            
            # print(f"Pool num for time range {time_range_str}: ", len(map_from_time_interval_to_filtered_alternative_list[time_range_str]))
            
            for pool in map_from_time_interval_to_filtered_alternative_list[time_range_str]:
                results_of_alternative_path = None
                executed_alternative_path_ids = []
                
                print_tips(
                    f"Start executing alternative paths for time range {time_range_str}.",
                    emoji="hourglass_flowing_sand",
                    text_color="yellow",
                    border=False
                )
                
                for alternative_path_id in pool:
                    # print(f"Alternative path num in pool: ", len(pool))
                    # print(f"Path id", alternative_path_id)
                    # print(f"Path: ", pool[alternative_path_id])
                    
                    print_tips(
                        f"Executing alternative path {alternative_path_id} for time range {time_range_str}.",
                        emoji="twisted_rightwards_arrows",
                        text_color="yellow",
                        border=False
                    )
                    
                    resutls_temp = execute_plan(
                        user_input=user_input,
                        data_structure_pool=data_structure_pool,
                        plan=pool[alternative_path_id]
                    )
                    
                    formatted_results_temp = format_results_to_dict(resutls_temp)
                    
                    executed_alternative_path_ids.append(alternative_path_id)
                    
                    if (len(formatted_results_temp) > 0 and find_interupt(formatted_results_temp) == False) or len(executed_alternative_path_ids) == len(pool):
                        results_of_alternative_path = copy.deepcopy(formatted_results_temp)
                        
                        print_tips(
                            f"Alternative path {alternative_path_id} for time range {time_range_str} executed successfully.",
                            emoji="white_check_mark",
                            text_color="yellow",
                            border=False
                        )
                        
                        break
                    else:
                        print_tips(
                            f"Alternative path {alternative_path_id} for time range {time_range_str} cannot generate valid results. Trying next alternative path if available.",
                            emoji="warning",
                            text_color="red",
                            border=False
                        )
                        
            
                if results_of_alternative_path is not None and len(results_of_alternative_path) > 0:
                    results_of_each_time_range[time_range_str].append(results_of_alternative_path)
                    
                
                print_tips(
                    f"Finished executing alternative paths for time range {time_range_str}.",
                    emoji="hourglass_done",
                    text_color="yellow",
                    border=False
                )
                
            
        return aggregate_results(results_of_each_time_range), unexecutable_time_ranges
                
    else:
        print("Do not use dynamic plan adaptation!")
        
        return execute_plan(
            user_input=user_input,
            data_structure_pool=data_structure_pool,
            plan=plan
        ), []
        

